{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = llm | parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {} # 특정 대화를 기록하기 위해 사용\n",
    "\n",
    "def get_session_history(sessionId: str) -> BaseChatMessageHistory:\n",
    "    if sessionId not in store: \n",
    "        store[sessionId] = InMemoryChatMessageHistory()\n",
    "    return store[sessionId]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"session_id\": \"chat\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"사용자의 질문에 2문장 이내로 짧게 대답해\"),\n",
    "    HumanMessage(content=\"오늘은 피자를 먹어야지!\"),\n",
    "    AIMessage(content=\"정말 좋은 생각이야. 음료는 무엇으로 할 거야?\"),\n",
    "    HumanMessage(content=\"내일은 수영을 가야지!\"),\n",
    "    AIMessage(content=\"수영이라니, 정말 좋은 운동이야. 수영장은 어디로 다녀?\"),\n",
    "    HumanMessage(content=\"주말에는 영화를 보러 갈 거야!\"),\n",
    "    AIMessage(content=\"주말이 벌써부터 기다려지겠는걸? 보려고 생각해둔 영화가 있어?\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'주말에 영화를 보러 간다고 했어! 어떤 영화 볼 계획이야?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(messages + \n",
    "  [HumanMessage(content=\"주말에 내가 뭐하러 간다고 했지?\")],\n",
    "  config=config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'주말에 네가 무엇을 하러 간다고 했는지 물어봤어.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"방금 내가 무슨 질문을 했지?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableWithMessageHistory] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableWithMessageHistory > chain:load_history] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableWithMessageHistory > chain:load_history] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableWithMessageHistory > chain:check_sync_or_async] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableWithMessageHistory > chain:check_sync_or_async > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableWithMessageHistory > chain:check_sync_or_async > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: 사용자의 질문에 2문장 이내로 짧게 대답해\\nHuman: 오늘은 피자를 먹어야지!\\nAI: 정말 좋은 생각이야. 음료는 무엇으로 할 거야?\\nHuman: 내일은 수영을 가야지!\\nAI: 수영이라니, 정말 좋은 운동이야. 수영장은 어디로 다녀?\\nHuman: 주말에는 영화를 보러 갈 거야!\\nAI: 주말이 벌써부터 기다려지겠는걸? 보려고 생각해둔 영화가 있어?\\nHuman: 주말에 내가 뭐하러 간다고 했지?\\nAI: 주말에 영화를 보러 간다고 했어! 어떤 영화 볼 계획이야?\\nHuman: 방금 내가 무슨 질문을 했지?\\nAI: 주말에 네가 무엇을 하러 간다고 했는지 물어봤어.\\nHuman: 수영은 언제가기로 했지?\\nAI: 수영은 내일 가기로 했다고 했어. 잘 다녀와!\\nHuman: 수영은 언제가기로 했지?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableWithMessageHistory > chain:check_sync_or_async > chain:RunnableSequence > llm:ChatOpenAI] [1.13s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"내일 수영을 가기로 했다고 했어.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"내일 수영을 가기로 했다고 했어.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 12,\n",
      "                \"prompt_tokens\": 259,\n",
      "                \"total_tokens\": 271,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--cfd0fdb5-b962-4f7f-80e5-61a9f0ecd1d9-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 259,\n",
      "              \"output_tokens\": 12,\n",
      "              \"total_tokens\": 271,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 12,\n",
      "      \"prompt_tokens\": 259,\n",
      "      \"total_tokens\": 271,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_34a54ae93c\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableWithMessageHistory > chain:check_sync_or_async > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableWithMessageHistory > chain:check_sync_or_async > chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"내일 수영을 가기로 했다고 했어.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableWithMessageHistory > chain:check_sync_or_async > chain:RunnableSequence] [1.13s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"내일 수영을 가기로 했다고 했어.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableWithMessageHistory > chain:check_sync_or_async] [1.14s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"내일 수영을 가기로 했다고 했어.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableWithMessageHistory] [1.14s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"내일 수영을 가기로 했다고 했어.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'내일 수영을 가기로 했다고 했어.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"수영은 언제가기로 했지?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

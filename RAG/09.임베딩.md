# 임베딩

임베딩(embedding) : 문서의 내용을 숫자 형태로 변환하는 것

임베딩을 거치면 실수들의 집합이 나오게 됨

## OpenAIEmbeddings

```py
from dotenv import load_dotenv
load_dotenv()

from langchain_openai import OpenAIEmbeddings

openai_embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

news = [
    "정치 : 최근 대선 후보 토론에서 양당의 입장이 강하게 충돌했습니다. 후보들은 세금 정책과 사회 복지 확대 여부를 두고 팽팽한 신경전을 벌였습니다. 전문가들은 이번 선거가 향후 10년간 정치 지형을 크게 변화시킬 것이라고 전망합니다.",
    "경제 : 세계적인 인플레이션 압박으로 각국 중앙은행들이 금리 인상에 나섰습니다. 특히 미국 연방준비제도는 예상보다 더 강력한 금리 인상을 단행하며 시장에 충격을 주었습니다. 이로 인해 주식과 채권 시장에서 대규모 매도세가 발생했습니다.",
    "과학 : 새로운 암 치료법이 임상시험에서 획기적인 성과를 거두었습니다. 연구팀은 유전자 편집 기술을 이용해 특정 암세포만을 표적으로 삼는 방법을 개발했습니다. 이 치료법이 상용화된다면 기존 치료법보다 부작용이 크게 줄어들 것으로 기대됩니다.",
    "기술 : 인공지능(AI) 기반 번역 서비스가 급속도로 발전하면서 글로벌 소통의 장벽이 낮아지고 있습니다. 최근 출시된 AI 번역기는 실시간으로 음성을 번역해주는 기능을 제공하며, 다양한 언어를 지원합니다. 이에 따라 다국적 비즈니스와 국제 회의의 효율성이 크게 향상될 것으로 보입니다.",
    "환경 : 지구 온난화로 인한 극단적인 기후 변화가 전 세계적으로 심각한 피해를 초래하고 있습니다. 북극 해빙이 급격히 녹고 있으며, 이로 인해 해수면 상승이 가속화되고 있습니다. 환경 단체들은 즉각적인 탄소 배출 감축이 필요하다고 경고하고 있습니다.",
    "사회 : 최근 젊은 층 사이에서 미니멀리즘 라이프스타일이 인기를 끌고 있습니다. 불필요한 물건을 줄이고 필수품만을 소유하는 이 방식은 스트레스 감소와 심리적 안정에 도움을 준다고 알려져 있습니다. 이에 따라 관련 제품과 서비스 시장도 확대되고 있습니다.",
    "국제 : 아시아-태평양 지역에서의 경제 협력이 강화되고 있습니다. 주요 국가들은 무역 장벽을 낮추고 공동 개발 프로젝트를 추진하며 상호 이익을 추구하고 있습니다. 그러나 중국과 미국 간의 갈등이 여전히 지역 안정에 큰 변수로 작용하고 있습니다.",
    "보건 : 최근 신종 바이러스의 확산이 일부 국가에서 급격히 증가하고 있습니다. 이에 따라 각국 정부는 예방접종 캠페인과 함께 강력한 방역 조치를 시행하고 있습니다. 보건 전문가들은 지속적인 모니터링과 빠른 대응이 필요하다고 강조하고 있습니다.",
    "문화 : 전통 예술과 현대 기술이 결합된 새로운 형태의 공연 예술이 인기를 끌고 있습니다. 디지털 기술을 활용한 무대 연출과 실시간 인터랙티브 요소가 관객의 몰입감을 높이고 있습니다. 이 같은 시도가 예술계에 신선한 변화를 가져오고 있습니다.",
    "우주 : NASA가 새롭게 발사한 우주 망원경이 태양계 외곽의 신비로운 행성을 발견했습니다. 과학자들은 이 행성의 대기에서 생명체의 존재를 암시하는 화합물을 발견했다고 발표했습니다. 이 발견은 우주 탐사에 새로운 이정표가 될 것으로 기대됩니다."
]

embeddings = openai_embeddings.embed_documents(news)
```

- `model` - 임베딩 모델을 의미함. 필요하면 다른 모델을 사용해도 됨

> 지원되는 임베딩 모델은 `tiktoken/model.py` 안에 있는 `MODEL_TO_ENCODING` 에 정의되어 있음
>
> <img width="476" height="391" alt="image" src="https://github.com/user-attachments/assets/588ee16d-d6b0-4bd4-b7b0-331392478305" />

```py
len(embeddings)
```

```
10
```

```py
len(embeddings[0])
```

```
1536
```

한 문장을 임베딩해서 나온 실수 집합의 길이가 1536이라는 의미

```py
embeddings[0][:10]
```

```
[0.02243948169052601,
 0.03620721772313118,
 0.0017182904994115233,
 0.03721356764435768,
 -0.005893575958907604,
 0.047662489116191864,
 0.0008189982618205249,
 0.042223911732435226,
 0.031068405136466026,
 0.020030664280056953]
```

#### 검색어 임베딩

```py
embedded_query = openai_embeddings.embed_query("대선 후보 토론")
embedded_query[:10]
```

```
[0.021439986303448677,
 0.005819424986839294,
 -0.010713612660765648,
 0.001410987228155136,
 -0.039791595190763474,
 0.02835693396627903,
 -0.02022760733962059,
 0.040761496871709824,
 0.028280362486839294,
 -0.03466131165623665]
```

### 유사도 검색

<img width="584" height="300" alt="image" src="https://github.com/user-attachments/assets/46c33545-b482-4d5f-8d8f-2a36df238bb0" />

일반적으로 코사인 유사도를 사용한다고 함

<img width="855" height="575" alt="image" src="https://github.com/user-attachments/assets/0d924748-9f37-498a-916a-4029e77d3978" />

원점으로 부터 각 점에 대한 직선을 그리고 그 각도가 가장 유사한 점을 찾음

```py
from numpy import dot
from numpy.linalg import norm # 선형대수 패키지

# 코사인 유사도 계산
def cosine_similarity(A, B):
    return dot(A, B) / (norm(A) * norm(B))

for embedding in embeddings:
  print(cosine_similarity(embedding, embedded_query))
```

```
0.16989606180271152
0.011073500926401319
0.06836814166549576
0.03466386460115435
0.1319263791506316
0.098827671684016
0.1100971449234042
0.0026307835246280587
0.20528114545291645
0.4683780607216249 # 우주 관련 news 가 가자 유사도가 높게 나옴
```
